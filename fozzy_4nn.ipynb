1)I left only the columns, the rest were considered bad (incomplete) for the models:

['ID', 'SKU', 'date', 'sales', 'Year', 'Карантин', 'USD', 'Euro', 'Выборы', 'is_monday',
 'is_tuesday', 'is_wednesday', 'is_thursday', 'is_friday', 'is_saturday', 'is_sunday', 'cityId']
2)
catboost + data>2021-07-01 + don`t use column price + devided data by category and fit 5 different models + MAE as loss
3)
data>2021-07-01, tested the hypothesis and it worked
drop price, because on the test 0 sales correspond to 0 prices and this overfit our tree
4)
CatBoostRegressor(iterations=1000, depth=16, learning_rate=0.8,task_type="GPU", loss_function="MAE")
trial and error
5)geo;data;weekday;product info





from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
train_final = pd.read_csv('drive/MyDrive/fozzy/train_final.csv')
train_final = train_final[train_final.date > '2021-07-01']
test_data = pd.read_csv('drive/MyDrive/fozzy/test_data.csv')
test_data['sales']=-1
result_data = pd.concat([train_final, test_data], axis=0)

sku_final = pd.read_csv('drive/MyDrive/fozzy/sku_final.csv')
sku_final = sku_final.drop(['commodity_group_caption_RU','commodity_group_caption_UKR','productType_caption_RU','productType_caption_UKR','productCategory_caption_UKR','productCategory_caption_RU'], axis=1)
sku_final = sku_final.drop(['countryOfOrigin','productType_caption_ENG','lagerUnitType_caption'], axis=1)
sku_final = sku_final.drop(['commodity_group','productCategoryId'], axis=1)
sku_final = sku_final.drop(['productCategory_caption_ENG'], axis=1)
sku_final = sku_final.drop(['countryOfOrigin_caption'], axis=1)
sku_final = sku_final.drop(['lagerUnitTypeId','lagerUnitQuantity','trademark'], axis=1)
sku_final = sku_final.drop(['brandId'], axis=1)

result_data = pd.merge(result_data, sku_final, how="left", on=["SKU","SKU"])

result = result_data.drop(['commodity_group_caption_ENG'], axis=1)
result = result.drop(['productTypeId','price'], axis=1)

geo_df = pd.read_csv('drive/MyDrive/fozzy/geo_params.csv')
sku_final = pd.read_csv('drive/MyDrive/fozzy/sku_final.csv')
merged_final = pd.merge(result, sku_final[['commodity_group_caption_ENG','SKU']], how="left", on=["SKU","SKU"])
result = merged_final

import pandas as pd
import datetime
!pip install catboost
from catboost import CatBoostRegressor
import numpy as np
from sklearn.preprocessing import LabelEncoder
del merged_final
del train_final
del sku_final
del result_data
del test_data



def mean_absolute_percentage_error_(y_true, y_pred): 
    return np.sum(np.abs(y_true - y_pred) / np.sum(y_true))

geoCluster_mass = result['commodity_group_caption_ENG'].unique()   
for i in range(0,len(geoCluster_mass)):
    mass = result.loc[(result['commodity_group_caption_ENG'] == geoCluster_mass[i])]
    data_dollar = pd.read_excel('drive/MyDrive/fozzy/dollar.xlsx')[1:]
    data_dollar.dropna(subset = ["Euro"], inplace=True)
    data_dollar=data_dollar.fillna(0)
    data_dollar=data_dollar.rename(columns={'Data': 'date'})
    data_dollar['date'] = data_dollar['date'].astype(str)
    outer_merged = pd.merge(mass, data_dollar, how="left", on=["date","date"])
    merged_final = outer_merged

    new_cols = ['is_monday', 'is_tuesday', 'is_wednesday', 'is_thursday', 'is_friday', 'is_saturday', 'is_sunday']
    day_cols_dict = {}
    months = []
    for date_str in merged_final.date:
        date = datetime.datetime.strptime(date_str, '%Y-%m-%d')
        for index, col_name in enumerate(new_cols):
            if col_name in day_cols_dict:
                day_cols_dict[col_name].append(date.weekday() == index)
            else:
                day_cols_dict[col_name] = [date.weekday() == index]
        months.append(date.month)
    for key, value in day_cols_dict.items():
        merged_final[key] = value
    merged_final['month'] = months


    anomaly_cluster = 681
    merged_final = merged_final[merged_final.geoCluster != anomaly_cluster]
    merged_geo = pd.merge(merged_final, geo_df, how='left', on=['geoCluster', 'geoCluster'])

    merged_geo = pd.concat([merged_geo, pd.get_dummies(merged_geo['commodity_group_caption_ENG'])], axis=1)
    merged_geo = pd.concat([merged_geo, pd.get_dummies(merged_geo['geoCluster'])], axis=1)
    merged_geo = pd.concat([merged_geo, pd.get_dummies(merged_geo['month'])], axis=1)
    #merged_geo = pd.concat([merged_geo, pd.get_dummies(merged_geo['brandId'])], axis=1)
    merged_geo = merged_geo.drop(['commodity_group_caption_ENG','geoCluster','month'], axis=1)
    result1 = merged_geo
    del merged_geo

    result1=result1.fillna(0)
    train_base = result1[result1.sales != -1]
    test_base = result1[result1.sales == -1]

    y = train_base['sales']
    X = train_base.drop(['sales'], axis=1)
    del train_base
    model = CatBoostRegressor(iterations=1000, depth=16, learning_rate=0.8,task_type="GPU", loss_function="MAE")
    model.fit(X.drop(['ID','date'], axis=1), y) 
    y_ = model.predict(X.drop(['ID','date'], axis=1))

    print(mean_absolute_percentage_error_(y, y_))
    print(i)    

    test_base_id = test_base[['ID','sales']]
    test_base_id['sales'] = model.predict(test_base.drop(['ID','date','sales'], axis=1))
    test_base_id.to_csv('drive/MyDrive/fozzy/out'+str(i)+'.csv',index=False)